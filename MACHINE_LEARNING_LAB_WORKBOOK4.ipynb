{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dwEAC-Y8oza"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. Procedure for Implementation of sklearn**"
      ],
      "metadata": {
        "id": "UFUN7ZNQ2xUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Procedure for Implementation of sklearn**\n",
        "machine learning models using scikit-learn, a powerful Python library for machine learning.\n",
        "\n",
        "**Installation:**\n",
        "Ensure you have Python 3.8 or newer installed.\n",
        "Make sure you have NumPy and SciPy installed (they are dependencies for scikit-learn).\n",
        "To install scikit-learn, use either of the following commands:\n",
        "Using pip:\n",
        "!pip install -U scikit-learn\n",
        "\n",
        "**Using conda:**\n",
        "conda install -c conda-forge scikit-learn\n",
        "\n",
        "**Loading a Dataset:**\n",
        "\n",
        "**A dataset consists of two main components:**\n",
        "\n",
        "**Features:**\n",
        "These are the variables (predictors or attributes) of your data. They can be represented by a feature matrix (commonly denoted as ‘X’).\n",
        "\n",
        "**Response:**\n",
        "This is the output variable that depends on the feature variables. It is represented by a response vector (commonly denoted as ‘y’).\n",
        "\n",
        "Scikit-learn comes with example datasets like iris\n",
        "(for classification) and boston house prices (for regression). You can load them as follows:"
      ],
      "metadata": {
        "id": "0pWUuMJl-Zvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data  # Feature matrix\n",
        "y = iris.target  # Response vector\n",
        "feature_names = iris.feature_names\n",
        "target_names = iris.target_names\n",
        "print(\"Feature names:\", feature_names)\n",
        "print(\"Target names:\", target_names)\n",
        "print(\"\\nType of X is:\", type(X))\n",
        "print(\"\\nFirst 5 rows of X:\\n\", X[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmKEogfY_JMV",
        "outputId": "b0f7c892-2753-4c45-9c58-fefd5b8f9d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Target names: ['setosa' 'versicolor' 'virginica']\n",
            "\n",
            "Type of X is: <class 'numpy.ndarray'>\n",
            "\n",
            "First 5 rows of X:\n",
            " [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to load an external dataset, you can use the pandas library for easy data manipulation.\n",
        "\n",
        "**Model Building:**\n",
        "Scikit-learn provides a unified interface for various machine learning\n",
        "algorithms,\n",
        "including classification,\n",
        "regression, and clustering.\n",
        "\n",
        "To build a model,\n",
        "choose an appropriate algorithm\n",
        "(e.g., SVM, random forests, k-means, etc.)\n",
        "and follow these steps:\n",
        "\n",
        "**Initialize the estimator:**\n",
        "For example, from sklearn.svm import SVC for support vector classification.\n",
        "**Fit the model:** Use estimator.fit(X, y) to train the model.\n",
        "\n",
        "**Make predictions:** Use estimator.predict(T) to predict outcomes for new data.\n",
        "\n",
        "Remember, scikit-learn simplifies the process of building and evaluating machine learning models, making it accessible to everyone!# New Section"
      ],
      "metadata": {
        "id": "m55b7JKQ_W16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. Write a Python program using Scikit-learn to split the dataset –\n",
        "prediction.csv**"
      ],
      "metadata": {
        "id": "QhZAEA4s4KUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(\"prediction.csv\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'X' contains features and 'y' contains the target variable\n",
        "X = df.drop(columns=[\"bmi\"])  # Replace \"target_column\" with your actual target column\n",
        "y = df[\"bmi\"]\n",
        "\n",
        "# Split the data (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
        "\n",
        "# Now you can use X_train, y_train for training and X_test, y_test for testing\n"
      ],
      "metadata": {
        "id": "BI8cnSWgBifF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18.Write a Python program using Scikit-learn to split the dataset Advertising.csv**"
      ],
      "metadata": {
        "id": "YFsx84N84YME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the dataset from the CSV file\n",
        "data = pd.read_csv('Advertising.csv')\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = data.drop(columns=['Sales'])  # Assuming 'Sales' is the target variable\n",
        "y = data['Sales']\n",
        "\n",
        "# Split the data into 70% training and 30% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(f\"Training data shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Testing data shape: X_test={X_test.shape}, y_test={y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsNgk4XJ4h_I",
        "outputId": "3cf5c40e-afc2-49dd-97d0-dce96fdb2f42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train=(140, 4), y_train=(140,)\n",
            "Testing data shape: X_test=(60, 4), y_test=(60,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. Write a Python program using Scikit-learn to split the dataset - iris.csv**"
      ],
      "metadata": {
        "id": "1oQBXGnZ6cyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into 50% training and 50% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(f\"Training data shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Testing data shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVDVODj26Yiu",
        "outputId": "4db4dbf0-8b9d-4292-ccfb-c50b8346ed34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train=(75, 4), y_train=(75,)\n",
            "Testing data shape: X_test=(75, 4), y_test=(75,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the dataset from the CSV file\n",
        "df = pd.read_csv('Real estate.csv')\n",
        "\n",
        "# Assuming 'Price' is the target variable, split the data\n",
        "X = df.drop(columns=['price'])\n",
        "y = df['price']\n",
        "\n",
        "# Split the data into 70% training and 30% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(f\"Training data shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Testing data shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TBrF6jZ65NL",
        "outputId": "914db371-fd34-4914-eea8-7dc328313ce9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train=(289, 7), y_train=(289,)\n",
            "Testing data shape: X_test=(125, 7), y_test=(125,)\n"
          ]
        }
      ]
    }
  ]
}